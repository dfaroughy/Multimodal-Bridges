{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Examine generated jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorclass import TensorMultiModal\n",
    "from datamodules.utils import JetFeatures, ParticleClouds\n",
    "from datamodules.aoj import AspenOpenJets\n",
    "\n",
    "dir_path = \"/home/df630/Multimodal-Bridges/experiments/results/comet/multimodal-jets/e5812472ffd44fa38ad3915f85806da2\"\n",
    "\n",
    "with open(dir_path + \"/metadata.json\", \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "test_path = dir_path + \"/data/test_sample.h5\"\n",
    "paths_path = dir_path + \"/data/paths_sample.h5\"\n",
    "\n",
    "paths = TensorMultiModal.load_from(paths_path)\n",
    "test = TensorMultiModal.load_from(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class MMDMetricMultiGPU:\n",
    "    def __init__(self, sigma=1.0, batch_size=5000, device_ids=[0, 1, 2, 3]):\n",
    "        \"\"\"\n",
    "        Multi-GPU MMD metric optimized for batch processing and distributed computing.\n",
    "\n",
    "        Parameters:\n",
    "        - sigma: Bandwidth parameter for the RBF kernel.\n",
    "        - batch_size: Number of particles per batch for kernel computation.\n",
    "        - device_ids: List of GPU device IDs to use (default: [0, 1, 2, 3]).\n",
    "        \"\"\"\n",
    "        self.sigma = sigma\n",
    "        self.batch_size = batch_size\n",
    "        self.device_ids = device_ids\n",
    "        self.world_size = len(device_ids)  # Number of GPUs\n",
    "\n",
    "    def _split_data(self, data, rank):\n",
    "        \"\"\"Split data into chunks based on rank.\"\"\"\n",
    "        num_samples = data.shape[0]\n",
    "        chunk_size = (num_samples + self.world_size - 1) // self.world_size  # Ensure all samples are assigned\n",
    "        start_idx = rank * chunk_size\n",
    "        end_idx = min(start_idx + chunk_size, num_samples)\n",
    "        return data[start_idx:end_idx]\n",
    "\n",
    "    def _rbf_kernel_batchwise(self, rank, X, Y, results_dict):\n",
    "        \"\"\"\n",
    "        Compute the RBF kernel between two datasets in batches using PyTorch GPU operations across multiple GPUs.\n",
    "        Each GPU only processes a subset of X and Y.\n",
    "        \"\"\"\n",
    "        device = f\"cuda:{rank}\"\n",
    "        X = self._split_data(X, rank).to(device)\n",
    "        Y = self._split_data(Y, rank).to(device)\n",
    "\n",
    "        num_X, num_Y = X.shape[0], Y.shape[0]\n",
    "        num_batches_X = (num_X + self.batch_size - 1) // self.batch_size\n",
    "        num_batches_Y = (num_Y + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "        mean_K = 0.0\n",
    "        count = 0\n",
    "\n",
    "        for i in tqdm(range(num_batches_X), desc=f\"GPU {rank}: RBF Kernel Batches\", position=rank):\n",
    "            start_i = i * self.batch_size\n",
    "            end_i = min((i + 1) * self.batch_size, num_X)\n",
    "            X_batch = X[start_i:end_i]\n",
    "\n",
    "            for j in range(num_batches_Y):\n",
    "                start_j = j * self.batch_size\n",
    "                end_j = min((j + 1) * self.batch_size, num_Y)\n",
    "                Y_batch = Y[start_j:end_j]\n",
    "\n",
    "                # Compute squared Euclidean distances and RBF kernel\n",
    "                dist_sq = torch.cdist(X_batch, Y_batch, p=2) ** 2\n",
    "                K_batch = torch.exp(-dist_sq / (2 * self.sigma ** 2))\n",
    "\n",
    "                mean_K += K_batch.sum().item()\n",
    "                count += K_batch.numel()\n",
    "\n",
    "        results_dict[rank] = mean_K / count\n",
    "\n",
    "    def _discrete_kernel_batchwise(self, rank, X, Y, results_dict):\n",
    "        \"\"\"\n",
    "        Compute the Kronecker delta kernel for discrete features in batches using GPU tensors across multiple GPUs.\n",
    "        Each GPU only processes a subset of X and Y.\n",
    "        \"\"\"\n",
    "        device = f\"cuda:{rank}\"\n",
    "        X = self._split_data(X, rank).to(device)\n",
    "        Y = self._split_data(Y, rank).to(device)\n",
    "\n",
    "        num_X, num_Y = X.shape[0], Y.shape[0]\n",
    "        num_batches_X = (num_X + self.batch_size - 1) // self.batch_size\n",
    "        num_batches_Y = (num_Y + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "        mean_K = 0.0\n",
    "        count = 0\n",
    "\n",
    "        for i in tqdm(range(num_batches_X), desc=f\"GPU {rank}: Discrete Kernel Batches\", position=rank):\n",
    "            start_i = i * self.batch_size\n",
    "            end_i = min((i + 1) * self.batch_size, num_X)\n",
    "            X_batch = X[start_i:end_i]\n",
    "\n",
    "            for j in range(num_batches_Y):\n",
    "                start_j = j * self.batch_size\n",
    "                end_j = min((j + 1) * self.batch_size, num_Y)\n",
    "                Y_batch = Y[start_j:end_j]\n",
    "\n",
    "                K_batch = (X_batch[:, None] == Y_batch[None, :]).float()\n",
    "                mean_K += K_batch.sum().item()\n",
    "                count += K_batch.numel()\n",
    "\n",
    "        results_dict[rank] = mean_K / count\n",
    "\n",
    "    def compute_mmd(self, gen, test):\n",
    "        \"\"\"\n",
    "        Compute the MMD metric between real and generated jet distributions using multi-GPU acceleration and batching.\n",
    "\n",
    "        Parameters:\n",
    "        - gen: TensorMultiModal (generated data).\n",
    "        - test: TensorMultiModal (test data).\n",
    "\n",
    "        Returns:\n",
    "        - MMD^2 score.\n",
    "        \"\"\"\n",
    "        # Extract valid (non-zero-padded) particles\n",
    "        gen_kin = gen.continuous[gen.mask.squeeze(-1) > 0]\n",
    "        test_kin = test.continuous[test.mask.squeeze(-1) > 0]\n",
    "        gen_flavor = gen.discrete[gen.mask.squeeze(-1) > 0]\n",
    "        test_flavor = test.discrete[test.mask.squeeze(-1) > 0]\n",
    "\n",
    "        # Create dictionaries to store results\n",
    "        rbf_results = mp.Manager().dict()\n",
    "        discrete_results = mp.Manager().dict()\n",
    "\n",
    "        # Launch multi-GPU processes for RBF kernel computation\n",
    "        processes = []\n",
    "        for rank in range(self.world_size):\n",
    "            p = mp.Process(target=self._rbf_kernel_batchwise, args=(rank, test_kin, test_kin, rbf_results))\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "\n",
    "        mean_K_XX = sum(rbf_results.values()) / self.world_size\n",
    "\n",
    "        # Launch multi-GPU processes for discrete kernel computation\n",
    "        processes = []\n",
    "        for rank in range(self.world_size):\n",
    "            p = mp.Process(target=self._discrete_kernel_batchwise, args=(rank, test_flavor, test_flavor, discrete_results))\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "\n",
    "        mean_K_XX *= sum(discrete_results.values()) / self.world_size\n",
    "\n",
    "        # Repeat for other kernel terms (mean_K_YY and mean_K_XY)\n",
    "        processes = []\n",
    "        for rank in range(self.world_size):\n",
    "            p = mp.Process(target=self._rbf_kernel_batchwise, args=(rank, gen_kin, gen_kin, rbf_results))\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "\n",
    "        mean_K_YY = sum(rbf_results.values()) / self.world_size\n",
    "\n",
    "        processes = []\n",
    "        for rank in range(self.world_size):\n",
    "            p = mp.Process(target=self._discrete_kernel_batchwise, args=(rank, gen_flavor, gen_flavor, discrete_results))\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "\n",
    "        mean_K_YY *= sum(discrete_results.values()) / self.world_size\n",
    "\n",
    "        processes = []\n",
    "        for rank in range(self.world_size):\n",
    "            p = mp.Process(target=self._rbf_kernel_batchwise, args=(rank, test_kin, gen_kin, rbf_results))\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "\n",
    "        mean_K_XY = sum(rbf_results.values()) / self.world_size\n",
    "\n",
    "        processes = []\n",
    "        for rank in range(self.world_size):\n",
    "            p = mp.Process(target=self._discrete_kernel_batchwise, args=(rank, test_flavor, gen_flavor, discrete_results))\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "\n",
    "        mean_K_XY *= sum(discrete_results.values()) / self.world_size\n",
    "\n",
    "        # Compute unbiased MMD^2\n",
    "        mmd2 = mean_K_XX + mean_K_YY - 2 * mean_K_XY\n",
    "        return mmd2\n",
    "\n",
    "# Example usage:\n",
    "# mmd_metric_multi_gpu = MMDMetricMultiGPU(sigma=1.0, batch_size=5000, device_ids=[0, 1, 2, 3])\n",
    "# mmd_score = mmd_metric_multi_gpu.compute_mmd(paths[-1], test)\n",
    "# print(\"MMD Score:\", mmd_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm \n",
    "\n",
    "class MMDMetricGPU:\n",
    "    def __init__(self, sigma=1.0, batch_size=5000, device=\"cuda\"):\n",
    "        \"\"\"\n",
    "        MMD metric optimized for GPU computation with batch processing.\n",
    "        \n",
    "        Parameters:\n",
    "        - sigma: Bandwidth parameter for the RBF kernel.\n",
    "        - batch_size: Number of particles per batch for kernel computation.\n",
    "        - device: \"cuda\" for GPU, \"cpu\" otherwise.\n",
    "        \"\"\"\n",
    "        self.sigma = sigma\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device  # \"cuda\" for GPU, \"cpu\" for CPU fallback\n",
    "\n",
    "    def _rbf_kernel_batchwise(self, X, Y):\n",
    "        \"\"\"\n",
    "        Compute the RBF kernel between two datasets in batches using PyTorch GPU operations.\n",
    "        Returns the mean kernel value.\n",
    "        \"\"\"\n",
    "        num_X, num_Y = X.shape[0], Y.shape[0]\n",
    "        num_batches_X = (num_X + self.batch_size - 1) // self.batch_size\n",
    "        num_batches_Y = (num_Y + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "        mean_K = 0.0\n",
    "        count = 0\n",
    "\n",
    "        # Wrap outer loop with tqdm for progress\n",
    "        for i in tqdm(range(num_batches_X), desc=\"RBF Kernel Batches (X)\"):\n",
    "            start_i = i * self.batch_size\n",
    "            end_i = min((i + 1) * self.batch_size, num_X)\n",
    "            X_batch = X[start_i:end_i].to(self.device)\n",
    "\n",
    "            for j in range(num_batches_Y):\n",
    "                start_j = j * self.batch_size\n",
    "                end_j = min((j + 1) * self.batch_size, num_Y)\n",
    "                Y_batch = Y[start_j:end_j].to(self.device)\n",
    "\n",
    "                # Compute squared Euclidean distances and RBF kernel\n",
    "                dist_sq = torch.cdist(X_batch, Y_batch, p=2) ** 2\n",
    "                K_batch = torch.exp(-dist_sq / (2 * self.sigma ** 2))\n",
    "                \n",
    "                mean_K += K_batch.sum().item()\n",
    "                count += K_batch.numel()\n",
    "\n",
    "        return mean_K / count\n",
    "\n",
    "    def _discrete_kernel_batchwise(self, X, Y):\n",
    "        \"\"\"Compute the Kronecker delta kernel for discrete features in batches using GPU tensors.\"\"\"\n",
    "        num_X, num_Y = X.shape[0], Y.shape[0]\n",
    "        num_batches_X = (num_X + self.batch_size - 1) // self.batch_size\n",
    "        num_batches_Y = (num_Y + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "        mean_K = 0\n",
    "        count = 0\n",
    "\n",
    "        for i in range(num_batches_X):\n",
    "            start_i = i * self.batch_size\n",
    "            end_i = min((i + 1) * self.batch_size, num_X)\n",
    "            X_batch = X[start_i:end_i].to(self.device)\n",
    "\n",
    "            for j in range(num_batches_Y):\n",
    "                start_j = j * self.batch_size\n",
    "                end_j = min((j + 1) * self.batch_size, num_Y)\n",
    "                Y_batch = Y[start_j:end_j].to(self.device)\n",
    "\n",
    "                K_batch = (X_batch[:, None] == Y_batch[None, :]).float()\n",
    "                mean_K += K_batch.sum()\n",
    "                count += K_batch.numel()\n",
    "\n",
    "        return mean_K / count  # Return the mean discrete kernel value\n",
    "\n",
    "    def compute_mmd(self, gen, test):\n",
    "        \"\"\"\n",
    "        Compute the MMD metric between real and generated jet distributions using GPU acceleration and batching.\n",
    "\n",
    "        Parameters:\n",
    "        - gen: TensorMultiModal (generated data).\n",
    "        - test: TensorMultiModal (test data).\n",
    "\n",
    "        Returns:\n",
    "        - MMD^2 score.\n",
    "        \"\"\"\n",
    "\n",
    "        # Extract valid (non-zero-padded) particles and move to GPU\n",
    "        gen_kin = gen.continuous[gen.mask.squeeze(-1) > 0].to(self.device)\n",
    "        test_kin = test.continuous[test.mask.squeeze(-1) > 0].to(self.device)\n",
    "        # gen_flavor = gen.discrete[gen.mask.squeeze(-1) > 0].to(self.device)\n",
    "        # test_flavor = test.discrete[test.mask.squeeze(-1) > 0].to(self.device)\n",
    "\n",
    "        # Compute kernel matrices in **batches** (to avoid memory issues)\n",
    "        mean_K_XX = self._rbf_kernel_batchwise(test_kin, test_kin) #* self._discrete_kernel_batchwise(test_flavor, test_flavor)\n",
    "        mean_K_YY = self._rbf_kernel_batchwise(gen_kin, gen_kin) #* self._discrete_kernel_batchwise(gen_flavor, gen_flavor)\n",
    "        mean_K_XY = self._rbf_kernel_batchwise(test_kin, gen_kin) #* self._discrete_kernel_batchwise(test_flavor, gen_flavor)\n",
    "\n",
    "        # Compute unbiased MMD^2\n",
    "        mmd2 = mean_K_XX + mean_K_YY - 2 * mean_K_XY\n",
    "        return mmd2.item()  # Convert to Python float\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "mmd_metric = MMDMetricMultiGPU(sigma=1.0, batch_size=5000, device_ids=[0,1,2,3])  # Reduce batch_size if memory is still an issue\n",
    "mmd_metric.compute_mmd(paths[-1], test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "markov_bridges",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
