trainer:
  max_epochs: 10
  gradient_clip_val: 1.0
  optimizer_name: AdamW
  optimizer_params:
    lr: 0.001
    weight_decay: 5.0e-5
    betas: [0.9, 0.999]
    eps: 1.e-8
    amsgrad: false
  scheduler_name: CosineAnnealingLR
  scheduler_params:
    T_max: 10
    eta_min: 1.0e-5
    last_epoch: -1

data:
  modality: multi-modal
  batch_size: 10
  split_ratios: [0.7, 0.3]  # train / val / test
  target_name: AspenOpenJets
  target_path: /home/df630/Multimodal-Bridges/tests/resources/
  target_train_files: 2016H_job0_mini.h5
  target_test_files: 2016H_job0_mini.h5
  source_name: MultiModalNoise
  source_path: null
  source_train_files: null
  source_test_files: null
  min_num_particles: 0
  max_num_particles: 128
  num_jets: 100
  dim_continuous: 3             
  dim_discrete: 1               
  dim_context_continuous: 5
  dim_context_discrete: 4      
  vocab_size: 8 
  vocab_size_context: 7  

model:
  bridge_continuous: UniformLinearFlow
  bridge_discrete: TelegraphBridge
  loss_weights: 'learnable'
  sigma: 0.0001
  gamma: 0.125
  num_timesteps: 200
  time_eps: 0.01

encoder:
  name: MultiModalEPiC
  num_blocks: 2
  dim_hidden_local: 128
  dim_hidden_glob: 32
  skip_connection: true
  dropout: 0.2
  data_augmentation: false
  embed_type_time: SinusoidalPositionalEncoding
  embed_type_continuous: MLP
  embed_type_discrete: LookupTableMLP
  embed_type_context_continuous: MLP
  embed_type_context_discrete: LookupTableMLP
  dim_emb_time: 32
  dim_emb_continuous: 16
  dim_emb_discrete: 12
  dim_emb_context_continuous: 5
  dim_emb_context_discrete: 2

comet_logger:
  api_key: 8ONjCXJ1ogsqG1UxQzKxYn7tz
  project_name: multimodal-jets
  workspace: dfaroughy
  save_dir: /home/df630/Multimodal-Bridges/experiments/results/comet
    
checkpoints:
  dirpath: null 
  monitor: val_loss      
  mode: min            
  save_top_k: 1
  filename: best-{epoch:02d}-{val_loss:.4f}
  save_last: true