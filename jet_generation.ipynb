{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3326da6f",
   "metadata": {},
   "source": [
    "# 1. Jet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8373ee76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: created experiment instance GaussNoise_to_AspenOpenJets_HybridEPiC_2024.12.17_14h16_1569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dario/Dropbox/PROJECTS/ML/CMB/src/cmb/datasets/utils.py:272: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  discrete = torch.tensor(discrete).long()\n"
     ]
    }
   ],
   "source": [
    "from utils import Configs\n",
    "from jetdata import JetDataclass\n",
    "\n",
    "config = Configs(\"configs.yaml\")\n",
    "\n",
    "# ...take small data samples:\n",
    "\n",
    "jets = JetDataclass(config=config)\n",
    "jets.preprocess()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69279944",
   "metadata": {},
   "source": [
    "### inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce324ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jets.source.display_cloud(idx=0, scale_marker=10.0)\n",
    "jets.target.display_cloud(idx=9, scale_marker=5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    jets.source.continuous.shape,\n",
    "    jets.target.continuous.shape,\n",
    "    jets.source.discrete.shape,\n",
    "    jets.target.discrete.shape,\n",
    "    jets.source.mask.shape,\n",
    "    jets.target.mask.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89539a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "sns.histplot(\n",
    "    jets.source.multiplicity,\n",
    "    element=\"step\",\n",
    "    fill=False,\n",
    "    discrete=True,\n",
    "    lw=0.75,\n",
    "    stat=\"density\",\n",
    "    color=\"r\",\n",
    "    log_scale=(False, False),\n",
    "    ax=ax,\n",
    "    label=\"source\",\n",
    ")\n",
    "sns.histplot(\n",
    "    jets.target.multiplicity,\n",
    "    element=\"step\",\n",
    "    fill=False,\n",
    "    discrete=True,\n",
    "    lw=0.75,\n",
    "    stat=\"density\",\n",
    "    log_scale=(False, False),\n",
    "    ax=ax,\n",
    "    label=\"target\",\n",
    ")\n",
    "ax.legend(fontsize=6)\n",
    "ax.set_xlabel(\"Particle Multiplicity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3bbe5b",
   "metadata": {},
   "source": [
    "# 2. Absorbing Bridge Matching\n",
    "Permutation equivariant architecture for point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0421dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dario/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/dario/anaconda3/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <6F778E65-02B4-30B0-8D19-83A1F2195F4D> /Users/dario/anaconda3/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <A84DFEFF-287E-3B94-A7DB-731FA5F9CBBC> /Users/dario/anaconda3/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import lightning as L\n",
    "from torch import nn\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from architecture import HybridEPiC\n",
    "from bridges import LinearUniformBridge, TelegraphBridge\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BridgeState:\n",
    "    time: torch.Tensor = None\n",
    "    continuous: torch.Tensor = None\n",
    "    discrete: torch.Tensor = None\n",
    "    absorbing: torch.Tensor = None\n",
    "\n",
    "    def append(self, state):\n",
    "        return BridgeState(\n",
    "            time=torch.cat([self.time, state.time], dim=0),\n",
    "            continuous=torch.cat([self.continuous, state.continuous], dim=0),\n",
    "            discrete=torch.cat([self.discrete, state.discrete], dim=0),\n",
    "            absorbing=torch.cat([self.absorbing, state.absorbing], dim=0),\n",
    "        )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OutputHeads:\n",
    "    continuous: torch.Tensor = None\n",
    "    discrete: torch.Tensor = None\n",
    "    absorbing: torch.Tensor = None\n",
    "\n",
    "\n",
    "class AbsorbingBridgeMatching(L.LightningModule):\n",
    "    \"\"\"Model for hybrid data with varying size\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.vocab_size = config.data.vocab_size.features\n",
    "\n",
    "        self.encoder = HybridEPiC(config)\n",
    "        self.bridge_continuous = LinearUniformBridge(config)\n",
    "        self.bridge_discrete = TelegraphBridge(config)\n",
    "        self.bridge_absorbing = TelegraphBridge(config)\n",
    "\n",
    "        self.loss_continuous_fn = nn.MSELoss(reduction=\"none\")\n",
    "        self.loss_discrete_fn = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, state, batch):\n",
    "        continuous, discrete, absorbing = self.encoder(\n",
    "            t=state.time,\n",
    "            x=state.continuous,\n",
    "            k=state.discrete,\n",
    "            mask=state.absorbing,\n",
    "            context_continuous=getattr(batch, \"context_continuous\", None),\n",
    "            context_discrete=getattr(batch, \"context_discrete\", None),\n",
    "        )\n",
    "        return OutputHeads(continuous, discrete, absorbing)\n",
    "\n",
    "    def sample_bridges(self, batch):\n",
    "        \"\"\"sample stochastic bridges\"\"\"\n",
    "        t = torch.rand(\n",
    "            batch.target_continuous.shape[0], device=batch.target_continuous.device\n",
    "        ).type_as(batch.target_continuous)\n",
    "        time = self.reshape_time(\n",
    "            t, batch.target_continuous\n",
    "        )  # shape: (b, 1,...) with len as len(x1)\n",
    "\n",
    "        continuous = self.bridge_continuous.sample(\n",
    "            time, batch.source_continuous, batch.target_continuous\n",
    "        )\n",
    "\n",
    "        discrete = self.bridge_discrete.sample(\n",
    "            time, batch.source_discrete, batch.target_discrete\n",
    "        )\n",
    "\n",
    "        absorbing = self.bridge_absorbing.sample(\n",
    "            time, batch.target_mask, batch.target_mask\n",
    "        )\n",
    "        return BridgeState(time, continuous, discrete, absorbing)\n",
    "\n",
    "    def loss_continuous(self, heads: OutputHeads, state: BridgeState, batch):\n",
    "        \"\"\"mean square error loss for velocity field\"\"\"\n",
    "        vector = heads.continuous\n",
    "        mask = heads.absorbing\n",
    "        \n",
    "        ut = self.bridge_continuous.drift(\n",
    "            t=state.time,\n",
    "            x=state.continuous,\n",
    "            x0=batch.source_continuous,\n",
    "            x1=batch.target_continuous,\n",
    "        ).to(vector.device)\n",
    "        loss_mse = self.loss_continuous_fn(vector, ut) * mask\n",
    "        return loss_mse.sum() / mask.sum()\n",
    "\n",
    "    def loss_discrete(self, heads: OutputHeads, batch):\n",
    "        \"\"\"cross-entropy loss for discrete state classifier\"\"\"\n",
    "        logits = heads.discrete\n",
    "        targets = batch.target_discrete\n",
    "        mask = heads.absorbing\n",
    "        logits = heads.discrete.reshape(-1, self.vocab_size)\n",
    "        targets = batch.target_discrete.reshape(-1).long()\n",
    "        targets = targets.to(logits.device)\n",
    "        mask = mask.reshape(-1)\n",
    "        loss_ce = self.loss_discrete_fn(logits, targets) * mask\n",
    "        return loss_ce.sum() / mask.sum()\n",
    "\n",
    "    def reshape_time(self, t, x):\n",
    "        if isinstance(t, (float, int)):\n",
    "            return t\n",
    "        else:\n",
    "            return t.reshape(-1, *([1] * (x.dim() - 1)))\n",
    "\n",
    "    # ...Lightning functions:\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        state = self.sample_bridges(batch)\n",
    "        heads = self.forward(state, batch)\n",
    "        loss_continous = self.loss_continuous(heads, state, batch)\n",
    "        loss_discrete = self.loss_discrete(heads, batch)\n",
    "        loss = loss_continous + loss_discrete\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        state = self.sample_bridges(batch)\n",
    "        heads = self.forward(state, batch)\n",
    "        loss_continous = self.loss_continuous(heads, state, batch)\n",
    "        loss_discrete = self.loss_discrete(heads, batch)\n",
    "        loss = loss_continous + loss_discrete\n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        \"\"\"generate target data from source data using trained dynamics\"\"\"\n",
    "        time_steps = torch.linspace(\n",
    "            0.0, 1.0 - self.config.pipeline.time_eps, self.config.pipeline.num_timesteps\n",
    "        )\n",
    "        delta_t = (time_steps[-1] - time_steps[0]) / (len(time_steps) - 1)\n",
    "        state = BridgeState(\n",
    "            time_steps[0],\n",
    "            batch.source_continuous,\n",
    "            batch.source_discrete,\n",
    "            batch.source_mask,\n",
    "        )\n",
    "        for time in time_steps[1:]:\n",
    "            state.time = torch.full(\n",
    "                (len(batch[0]), 1), time.item(), device=batch[0].device\n",
    "            )\n",
    "            heads = self.forward(state, batch)\n",
    "            state = self.bridge_continuous.solver_step(state, heads, delta_t)\n",
    "            state = self.bridge_discrete.solver_step(state, heads, delta_t)\n",
    "        return state\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(), lr=self.config.train.optimizer.params.lr\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=self.config.train.scheduler.params.T_max,  # Adjust as needed\n",
    "            eta_min=self.config.train.scheduler.params.eta_min,  # Adjust as needed\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7184170e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: building dataloaders...\n",
      "INFO: train/val/test split ratios: 0.7/0.1/0.2\n",
      "INFO: train size: 47736, validation size: 6819, testing sizes: 13640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dario/anaconda3/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "from dataloader import DataloaderModule\n",
    "\n",
    "dataloader = DataloaderModule(config=config, dataclass=jets)\n",
    "databatch = next(dataloader.train.__iter__())\n",
    "abm = AbsorbingBridgeMatching(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e354df3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name               | Type             | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | encoder            | HybridEPiC       | 826 K  | train\n",
      "1 | loss_continuous_fn | MSELoss          | 0      | train\n",
      "2 | loss_discrete_fn   | CrossEntropyLoss | 0      | train\n",
      "----------------------------------------------------------------\n",
      "826 K     Trainable params\n",
      "0         Non-trainable params\n",
      "826 K     Total params\n",
      "3.305     Total estimated model params size (MB)\n",
      "70        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93748e6bd5774268b5540fb15386e319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dario/anaconda3/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/dario/anaconda3/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd38a3e0dd5243c997a2ad199380f31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5576d1dc0364880b35fa55b27bce36d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "# from lightning.pytorch.loggers import MLFlowLogger\n",
    "\n",
    "# mlflow_logger = MLFlowLogger(\n",
    "#     experiment_name=config.experiment.name,\n",
    "#     tracking_uri=\"file:./results\",  # or some external tracking server URI\n",
    "# )\n",
    "\n",
    "model = Trainer(\n",
    "    max_epochs=1,\n",
    "    log_every_n_steps=1,\n",
    "    #  logger=mlflow_logger,\n",
    "    accelerator=config.train.device,\n",
    "    devices=1,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    abm,\n",
    "    train_dataloaders=dataloader.train,\n",
    "    val_dataloaders=dataloader.valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58ef0710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dario/anaconda3/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:475: Your `predict_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/Users/dario/anaconda3/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63561b845f047518ea96ee93abca0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     49\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:897\u001b[0m, in \u001b[0;36mTrainer._predict_impl\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    894\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    895\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn, ckpt_path, model_provided\u001b[39m=\u001b[39mmodel_provided, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    896\u001b[0m )\n\u001b[0;32m--> 897\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    899\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    983\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1020\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[0;32m-> 1020\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1021\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:178\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 178\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/lightning/pytorch/loops/prediction_loop.py:124\u001b[0m, in \u001b[0;36m_PredictionLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[39m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n\u001b[1;32m    125\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m     \u001b[39m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/lightning/pytorch/loops/prediction_loop.py:253\u001b[0m, in \u001b[0;36m_PredictionLoop._predict_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    248\u001b[0m step_args \u001b[39m=\u001b[39m (\n\u001b[1;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, \u001b[39m\"\u001b[39m\u001b[39mpredict_step\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    251\u001b[0m     \u001b[39melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    252\u001b[0m )\n\u001b[0;32m--> 253\u001b[0m predictions \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, \u001b[39m\"\u001b[39;49m\u001b[39mpredict_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mstep_args)\n\u001b[1;32m    254\u001b[0m \u001b[39mif\u001b[39;00m predictions \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    321\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:437\u001b[0m, in \u001b[0;36mStrategy.predict_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_redirection(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module, \u001b[39m\"\u001b[39m\u001b[39mpredict_step\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 437\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module\u001b[39m.\u001b[39;49mpredict_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn[2], line 152\u001b[0m, in \u001b[0;36mAbsorbingBridgeMatching.predict_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    149\u001b[0m state\u001b[39m.\u001b[39mtime \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfull(\n\u001b[1;32m    150\u001b[0m     (\u001b[39mlen\u001b[39m(batch[\u001b[39m0\u001b[39m]), \u001b[39m1\u001b[39m), time\u001b[39m.\u001b[39mitem(), device\u001b[39m=\u001b[39mbatch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdevice\n\u001b[1;32m    151\u001b[0m )\n\u001b[0;32m--> 152\u001b[0m heads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(state, batch)\n\u001b[1;32m    153\u001b[0m state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbridge_continuous\u001b[39m.\u001b[39msolver_step(state, heads, delta_t)\n",
      "Cell \u001b[0;32mIn[2], line 52\u001b[0m, in \u001b[0;36mAbsorbingBridgeMatching.forward\u001b[0;34m(self, state, batch)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, state, batch):\n\u001b[0;32m---> 52\u001b[0m     continuous, discrete, absorbing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m     53\u001b[0m         t\u001b[39m=\u001b[39;49mstate\u001b[39m.\u001b[39;49mtime,\n\u001b[1;32m     54\u001b[0m         x\u001b[39m=\u001b[39;49mstate\u001b[39m.\u001b[39;49mcontinuous,\n\u001b[1;32m     55\u001b[0m         k\u001b[39m=\u001b[39;49mstate\u001b[39m.\u001b[39;49mdiscrete,\n\u001b[1;32m     56\u001b[0m         mask\u001b[39m=\u001b[39;49mstate\u001b[39m.\u001b[39;49mabsorbing,\n\u001b[1;32m     57\u001b[0m         context_continuous\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(batch, \u001b[39m\"\u001b[39;49m\u001b[39mcontext_continuous\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m     58\u001b[0m         context_discrete\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(batch, \u001b[39m\"\u001b[39;49m\u001b[39mcontext_discrete\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m     59\u001b[0m     )\n\u001b[1;32m     60\u001b[0m     \u001b[39mreturn\u001b[39;00m OutputHeads(continuous, discrete, absorbing)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Dropbox/PROJECTS/ML/CMB/examples/markov-bridges/architecture.py:34\u001b[0m, in \u001b[0;36mHybridEPiC.forward\u001b[0;34m(self, t, x, k, mask, context_continuous, context_discrete)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m     32\u001b[0m     \u001b[39mself\u001b[39m, t, x, k, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, context_continuous\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, context_discrete\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m     33\u001b[0m ):\n\u001b[0;32m---> 34\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepic(t, x, k, context_continuous, context_discrete, mask)\n\u001b[1;32m     35\u001b[0m     continuous_head \u001b[39m=\u001b[39m h[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_features_continuous]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Dropbox/PROJECTS/ML/CMB/examples/markov-bridges/architecture.py:121\u001b[0m, in \u001b[0;36mEPiC.forward\u001b[0;34m(self, t, x, k, context_continuous, context_discrete, mask)\u001b[0m\n\u001b[1;32m    118\u001b[0m x_local_emb, context_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(\n\u001b[1;32m    119\u001b[0m     t, x, k, context_continuous, context_discrete, mask\n\u001b[1;32m    120\u001b[0m )\n\u001b[0;32m--> 121\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepic(x_local_emb, context_emb, mask)\n\u001b[1;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m h\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Dropbox/PROJECTS/ML/CMB/examples/markov-bridges/architecture.py:185\u001b[0m, in \u001b[0;36mEPiCNetwork.forward\u001b[0;34m(self, x_local, context, mask)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_blocks):\n\u001b[0;32m--> 185\u001b[0m     x_local, x_global \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepic_layers[i](x_local, x_global, context, mask)\n\u001b[1;32m    186\u001b[0m     x_local \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m x_local_skip\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Dropbox/PROJECTS/ML/CMB/examples/markov-bridges/architecture.py:270\u001b[0m, in \u001b[0;36mEPiC_layer.forward\u001b[0;34m(self, x_local, x_global, context, mask)\u001b[0m\n\u001b[1;32m    269\u001b[0m x_localCATglobal \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x_local, x_global2local, x_context2local], \u001b[39m2\u001b[39m)\n\u001b[0;32m--> 270\u001b[0m x_local1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_fn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc_local1(x_localCATglobal))\n\u001b[1;32m    271\u001b[0m x_local \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_fn(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_local2(x_local1) \u001b[39m+\u001b[39m x_local)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1562\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generation \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(abm, dataloaders\u001b[39m=\u001b[39;49mdataloader\u001b[39m.\u001b[39;49mtest)\n\u001b[1;32m      3\u001b[0m \u001b[39m# predictions is a list of outputs from each batch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# For example, if your predict_step returns a state for each batch:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, state \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(generation):\n\u001b[1;32m      6\u001b[0m     \u001b[39m# Here `state` is the BridgeState returned by predict_step for that batch.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[39m# You can now run evaluation metrics or further processing.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[39m# `state.continuous`, `state.discrete`, etc. are now accessible.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:858\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[1;32m    857\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 858\u001b[0m \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    859\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_impl, model, dataloaders, datamodule, return_predictions, ckpt_path\n\u001b[1;32m    860\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[39m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     exit(\u001b[39m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "generation = model.predict(abm, dataloaders=dataloader.test)\n",
    "\n",
    "# predictions is a list of outputs from each batch\n",
    "# For example, if your predict_step returns a state for each batch:\n",
    "for batch_idx, state in enumerate(generation):\n",
    "    # Here `state` is the BridgeState returned by predict_step for that batch.\n",
    "    # You can now run evaluation metrics or further processing.\n",
    "    # `state.continuous`, `state.discrete`, etc. are now accessible.\n",
    "    print(f\"Batch {batch_idx} generated data:\", state.continuous.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
